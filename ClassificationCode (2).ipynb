{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8c89576-e688-44f3-855c-cba10540bdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import seaborn as sborn\n",
    "import plotly.offline as pltoff\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "import plotly.graph_objs as grph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9c037bc-c564-4f07-9cba-780458fdff3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_MissingValues' from 'sklearn.utils._param_validation' (C:\\Users\\Y Rohith Reddy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\__init__.py:52\u001b[0m\n\u001b[0;32m     48\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartial import of imblearn during the build process.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     53\u001b[0m         combine,\n\u001b[0;32m     54\u001b[0m         ensemble,\n\u001b[0;32m     55\u001b[0m         exceptions,\n\u001b[0;32m     56\u001b[0m         metrics,\n\u001b[0;32m     57\u001b[0m         over_sampling,\n\u001b[0;32m     58\u001b[0m         pipeline,\n\u001b[0;32m     59\u001b[0m         tensorflow,\n\u001b[0;32m     60\u001b[0m         under_sampling,\n\u001b[0;32m     61\u001b[0m         utils,\n\u001b[0;32m     62\u001b[0m     )\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FunctionSampler\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\combine\\__init__.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"The :mod:`imblearn.combine` provides methods which combine\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mover-sampling and under-sampling.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_enn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTEENN\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_tomek\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTETomek\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEENN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTETomek\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\combine\\_smote_enn.py:12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_X_y\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSampler\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseOverSampler\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\base.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticlass\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_classification_targets\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_sampling_strategy, check_target_type\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArraysTransformer\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSamplerMixin\u001b[39;00m(BaseEstimator, metaclass\u001b[38;5;241m=\u001b[39mABCMeta):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\utils\\_param_validation.py:908\u001b[0m\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate_valid_param  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m    907\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m--> 908\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    909\u001b[0m     HasMethods,\n\u001b[0;32m    910\u001b[0m     Hidden,\n\u001b[0;32m    911\u001b[0m     Interval,\n\u001b[0;32m    912\u001b[0m     Options,\n\u001b[0;32m    913\u001b[0m     StrOptions,\n\u001b[0;32m    914\u001b[0m     _ArrayLikes,\n\u001b[0;32m    915\u001b[0m     _Booleans,\n\u001b[0;32m    916\u001b[0m     _Callables,\n\u001b[0;32m    917\u001b[0m     _CVObjects,\n\u001b[0;32m    918\u001b[0m     _InstancesOf,\n\u001b[0;32m    919\u001b[0m     _IterablesNotString,\n\u001b[0;32m    920\u001b[0m     _MissingValues,\n\u001b[0;32m    921\u001b[0m     _NoneConstraint,\n\u001b[0;32m    922\u001b[0m     _PandasNAConstraint,\n\u001b[0;32m    923\u001b[0m     _RandomStates,\n\u001b[0;32m    924\u001b[0m     _SparseMatrices,\n\u001b[0;32m    925\u001b[0m     _VerboseHelper,\n\u001b[0;32m    926\u001b[0m     make_constraint,\n\u001b[0;32m    927\u001b[0m     validate_params,\n\u001b[0;32m    928\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_MissingValues' from 'sklearn.utils._param_validation' (C:\\Users\\Y Rohith Reddy\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py)"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86ab6de-63f7-4b99-a6ef-8aeceecabd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Plotly for offline use\n",
    "pltoff.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5d9005-5b99-4a95-8cc0-973bed26f49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from packaging import version \n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, message=\"distutils Version classes are deprecated. Use packaging.version instead.\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning, message=\"`np.bool8` is a deprecated alias for the `np.bool_`.\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "warnings.filterwarnings(\"once\")\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "warnings.filterwarnings(\"default\")\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ResourceWarning)  # Suppress ResourceWarnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='sklearn')\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"is_sparse is deprecated and will be removed in a future version.*\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"The 'S' method for sort is deprecated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f99412f-299d-450d-8c76-71047423dd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Loading of dataset using pandas.\n",
    "'''\n",
    "data = pds.read_csv(\"breast-cancer-wisconsin.csv\")\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513c62e9-f632-4383-a46e-309605e99f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dataset Shape.\n",
    "'''\n",
    "print(\"Number of rows in Dataset\",data.shape[0])\n",
    "print(\"Number of columns in Dataset\", data.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fcda81-657f-436d-805b-0faa790be667",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Overview of the data\n",
    "'''\n",
    "print(\"\\nData Types of Attributes present in dataset:\\n\", data.dtypes)\n",
    "print(\"\\nSummary of the data:\\n\", data.describe())\n",
    "total_missing_values = data.isnull().sum()\n",
    "print(\"\\nMissing Values present in data:\\n\", total_missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c486faa-354b-42ac-ad30-7e0cebd2c7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = data.nunique()\n",
    "print(\"\\nCount of Unique Values of features:\\n\", unique_values)\n",
    "\n",
    "'''\n",
    "Visualizing unique value counts\n",
    "'''\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "data.nunique().plot(kind='bar', color='lightblue')\n",
    "\n",
    "plt.title('Unique Values of Each Attribute column')\n",
    "\n",
    "plt.xlabel('Attributes in dataset')\n",
    "\n",
    "plt.ylabel('Unique Values of attributes')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde21c78-42c8-4483-a935-879fb9f342fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "Encoding the 'diagnosis' \n",
    "Converting categorical values of 'diagnosis' attribute to numerical values\n",
    "Assigning 1 to Malignant patients\n",
    "Assigning 0 to Benign patients\n",
    "'''\n",
    "data['diagnosis'].replace({'B': 0, 'M': 1}, inplace=True)\n",
    "\n",
    "\n",
    "'''\n",
    " Visualising Number of malignant and Benign count.\n",
    " Plotting the graph using matplotlib library.\n",
    " '''\n",
    "distr_diag = data.groupby('diagnosis').size()\n",
    "plt.figure(figsize=(10, 8))\n",
    "distr_diag.plot(kind='bar', color=['salmon', 'lightgreen'])\n",
    "plt.title('Distribution of Diagnosis')\n",
    "plt.xticks(ticks=[0, 1], labels=['Benign', 'Malignant'], rotation=0)\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Diagnosis Feature')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d99ccc-a8c7-442b-977a-5eed43b0e545",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_column = 'id'\n",
    "dependent_feature = 'diagnosis'\n",
    "\n",
    "# Separate categorical and numerical columns\n",
    "cate_colmns = []\n",
    "for i in data.columns:\n",
    "    if data[i].dtype == 'object':\n",
    "        cate_colmns.append(i)\n",
    "\n",
    "numerical_columns = []\n",
    "excluded_columns = cate_colmns + [id_column, dependent_feature]\n",
    "for i in data.columns:\n",
    "    if i not in excluded_columns:\n",
    "        numerical_columns.append(i)\n",
    "\n",
    "\n",
    "bin_colmns = []\n",
    "for i in data.columns:\n",
    "    if data[i].nunique() == 2:\n",
    "        bin_colmns.append(i)\n",
    "\n",
    "multi_value_cols = []\n",
    "for i in cate_colmns:\n",
    "    if i not in bin_colmns:\n",
    "        multi_value_cols.append(i)\n",
    "\n",
    "\n",
    "# Label encode binary columns\n",
    "label_encoder = LabelEncoder()\n",
    "data[bin_colmns] = data[bin_colmns].apply(lambda col: label_encoder.fit_transform(col))\n",
    "\n",
    "\n",
    "# # Convert multi-value categorical columns to one-hot encoded format\n",
    "# if multi_value_cols:  # Check if there are any multi-value columns to encode\n",
    "#     data = pd.concat([data.drop(columns=multi_value_cols), pd.get_dummies(data[multi_value_cols])], axis=1)\n",
    "# else:\n",
    "#     print(\"No multi-value categorical columns to encode.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a250da3a-7409-4e11-ad96-fa5bacc265a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary class for scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the scaling object for numerical data\n",
    "numerical_scaler = StandardScaler()\n",
    "\n",
    "# Perform the fit and transform operations in one step for the numerical columns\n",
    "transformed_numerical_data = numerical_scaler.fit_transform(data.loc[:, numerical_columns])\n",
    "\n",
    "# Construct a DataFrame from the scaled numerical data\n",
    "scaled_numerical_dataframe = pds.DataFrame(transformed_numerical_data, columns=numerical_columns, index=data.index)\n",
    "\n",
    "# Combine the original data (excluding old numerical columns) with the new scaled numerical data\n",
    "dataset_scaled = data.drop(columns=numerical_columns).join(scaled_numerical_dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58017a81-a99d-4c33-adcc-411e82b5444b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Correlation matrix visualization\n",
    "'''\n",
    "feat_corrltm = dataset_scaled.corr()\n",
    "\n",
    "mat_clmns = feat_corrltm.columns.tolist()\n",
    "\n",
    "cor_lst_arr = feat_corrltm.values\n",
    "\n",
    "\n",
    "trace = grph.Heatmap(z=cor_lst_arr, x=mat_clmns, y=mat_clmns,\n",
    "                     colorscale=\"RdYlBu\",  \n",
    "                     colorbar=dict(title=\"Correlation coefficient\",titleside=\"right\"))\n",
    "\n",
    "\n",
    "layout = grph.Layout( height=710, width=710)\n",
    "\n",
    "fig = grph.Figure(data=[trace], layout=layout)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed4a046-34d3-4ee6-9e8c-6d3515c37c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "train data and test data splitting.\n",
    "'''\n",
    "trning_dt,tsting_dt = train_test_split(dataset_scaled,test_size = .25 ,random_state = 42)\n",
    "    \n",
    "# Extracting feature columns (independent variables)\n",
    "independent_features = []\n",
    "excluded_features = id_column + dependent_feature\n",
    "for val in dataset_scaled.columns:\n",
    "    if val not in excluded_features:\n",
    "        independent_features.append(val)\n",
    "\n",
    "# Separating independent and dependent variables for training set\n",
    "x_trning_dt_set = trning_dt[independent_features]\n",
    "y_trning_dt_set = trning_dt[dependent_feature]\n",
    "\n",
    "# Separating independent and dependent variables for testing set\n",
    "x_tsting_dt_set = tsting_dt[independent_features]\n",
    "y_tsting_dt_set = tsting_dt[dependent_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6d91ed-f885-443e-8905-ea946183a901",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_confus_mtrx(input,title):\n",
    "    fig, dimen = plt.subplots(figsize=(6, 4))\n",
    "    map_coloring = plt.cm.Blues\n",
    "    im = dimen.imshow(input, interpolation='nearest', cmap=map_coloring)\n",
    "\n",
    "    # Add a color bar to the plot\n",
    "    plt.colorbar(im, ax=dimen)\n",
    "\n",
    "    # Define the label names for the input\n",
    "    label_cls = ['Positive', 'Negative']\n",
    "\n",
    "    # Set tick marks for class labels\n",
    "    axis_ticks = np.arange(len(label_cls))\n",
    "    plt.xticks(axis_ticks, label_cls, rotation=90)\n",
    "    plt.yticks(axis_ticks, label_cls)\n",
    "\n",
    "    # Set axis labels and the title\n",
    "    dimen.set_xlabel('Predicted Labels')\n",
    "    dimen.set_ylabel('True Labels')\n",
    "    dimen.set_title(title)\n",
    "\n",
    "    # Define text formatting inside the input boxes\n",
    "    val = 'd'  # Decimal integer\n",
    "    threshold_val = input.max() / 2.\n",
    "    # Iterate over data dimensions for text annotations\n",
    "    dimen1 = input.shape[0]\n",
    "    dimen2 = input.shape[1]\n",
    "    for row in range(dimen1):\n",
    "        for col in range(dimen2):\n",
    "            dimen.text(col, row, format(input[row, col], val),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if input[row, col] > threshold_val else \"black\")\n",
    "\n",
    "    # Improve layout to prevent clipping of tick-labels\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505cb01c-1eb1-4144-b8d5-809a6db4f062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fprates, tprates, roc_auc):\n",
    "    plt.figure(figsize=(7, 5))  \n",
    "    plt.plot(fprates, tprates, lw=2, color='skyblue', label='Receiver Operating Characteristic Curve (AUC = %0.4f)' % roc_auc)  \n",
    "    plt.plot([0, 1], [0, 1],lw=2, color='darkgreen', linestyle='dotted') \n",
    "    \n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc='lower right')  # Move legend to upper left\n",
    "    plt.grid(False)  # Add a grid for better readability\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6cb44f-c3f8-4e23-a0b3-6b07a313ac2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(coefficients, features, title):\n",
    "    \n",
    "    Feature_Importance = pds.DataFrame({'Coefficients': coefficients.ravel(),'Features': features})\n",
    "    plot=Feature_Importance.sort_values(by='Coefficients',ascending=False)\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(9, 5))\n",
    "    plt.bar(plot['Features'], plot['Coefficients'], color='green')\n",
    "    plt.xlabel('Features present in Dataset.')\n",
    "    plt.ylabel('Coefficient Values')\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2f991d-deb9-4c81-9393-8d9f517eded1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fprate_curves = []\n",
    "tprate_curves = []\n",
    "auc_curves = []\n",
    "def classification_algo_with_feature_imp(algo, x_trning_dt_set, x_tsting_dt_set, y_trning_dt_set, y_tsting_dt_set, independent_features, cf_notation,title):\n",
    "    \n",
    "    algo.fit(x_trning_dt_set, y_trning_dt_set)\n",
    "    \n",
    "    # Training set predictions and probabilities\n",
    "    train_set_predic = algo.predict(x_trning_dt_set)\n",
    "    train_set_probs = algo.predict_proba(x_trning_dt_set)\n",
    "    \n",
    "   \n",
    "    \n",
    "    # Classification report for training set\n",
    "    print(\"\\nClassification Report for Training Set:\")\n",
    "    print(classification_report(y_trning_dt_set, train_set_predic))\n",
    "\n",
    "    # Confusion matrix and plots for training set\n",
    "    print(\"Confusion Matrix for Training Set:\")\n",
    "    train_conf_matrix = confusion_matrix(y_trning_dt_set, train_set_predic)\n",
    "    plot_confus_mtrx(train_conf_matrix, \"Confusion Matrix for Training Set\")\n",
    "    \n",
    "     # Training set accuracy\n",
    "    train_set_accu = accuracy_score(y_trning_dt_set, train_set_predic)\n",
    "    print(\"Training Accuracy:\", train_set_accu)\n",
    "\n",
    "    # ROC curve for training set\n",
    "    fprate_train_set, tprate_train_set, _ = roc_curve(y_trning_dt_set, train_set_probs[:, 1])\n",
    "    roc_auc_train_set = roc_auc_score(y_trning_dt_set, train_set_predic)\n",
    "    print(\"Area under ROC curve:\", roc_auc_train_set)\n",
    "    plot_roc_curve(fprate_train_set, tprate_train_set, roc_auc_train_set)\n",
    "    \n",
    "    # Test set predictions and probabilities\n",
    "    test_set_predic = algo.predict(x_tsting_dt_set)\n",
    "    test_set_prob = algo.predict_proba(x_tsting_dt_set)\n",
    "\n",
    "    # Classification report for test set\n",
    "    print(\"\\nClassification Report for Test Set:\")\n",
    "    print(classification_report(y_tsting_dt_set, test_set_predic))\n",
    "\n",
    "    # Confusion matrix and plots for test set\n",
    "    print(\"\\nConfusion Matrix for Test Set:\")\n",
    "    tst_confu_mat = confusion_matrix(y_tsting_dt_set, test_set_predic)\n",
    "    plot_confus_mtrx(tst_confu_mat, \"Confusion Matrix for Test Set\")\n",
    "\n",
    "    # Accuracy and ROC curve for test set\n",
    "    accuracy = accuracy_score(y_tsting_dt_set, test_set_predic)\n",
    "    print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "    roc_auc_test_set = roc_auc_score(y_tsting_dt_set, test_set_predic)\n",
    "    print(\"Area under ROC curve:\", roc_auc_test_set)\n",
    "    auc_curves.append(roc_auc_test_set)\n",
    "\n",
    "    fprate, tprate, _ = roc_curve(y_tsting_dt_set, test_set_prob[:, 1])\n",
    "    tprate_curves.append(tprate)\n",
    "    fprate_curves.append(fprate)\n",
    "    plot_roc_curve(fprate, tprate, roc_auc_test_set)\n",
    "\n",
    "    # Feature coefficients or importances\n",
    "    if cf_notation == \"coefficients\":\n",
    "        feature_vals = algo.coef_.ravel()\n",
    "    elif cf_notation == \"features\":\n",
    "        feature_vals = algo.feature_importances_\n",
    "    \n",
    "    # Plot feature importances using the separated function\n",
    "    \n",
    "    plot_feature_importances(feature_vals, independent_features,title)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65215af0-f0d5-49af-aaf4-1f7788fdc96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fprate_curves = []\n",
    "tprate_curves = []\n",
    "auc_curves = []\n",
    "def classification_algo_without_feature_imp(algo, x_trning_dt_set, x_tsting_dt_set, y_trning_dt_set, y_tsting_dt_set,title):\n",
    "    \n",
    "    algo.fit(x_trning_dt_set, y_trning_dt_set)\n",
    "    \n",
    "    # Training set predictions and probabilities\n",
    "    train_set_predic = algo.predict(x_trning_dt_set)\n",
    "    train_set_probs = algo.predict_proba(x_trning_dt_set)\n",
    "    \n",
    "   \n",
    "    \n",
    "    # Classification report for training set\n",
    "    print(\"\\nClassification Report for Training Set:\")\n",
    "    print(classification_report(y_trning_dt_set, train_set_predic))\n",
    "\n",
    "    # Confusion matrix and plots for training set\n",
    "    print(\"Confusion Matrix for Training Set:\")\n",
    "    train_conf_matrix = confusion_matrix(y_trning_dt_set, train_set_predic)\n",
    "    plot_confus_mtrx(train_conf_matrix, \"Confusion Matrix for Training Set\")\n",
    "    \n",
    "     # Training set accuracy\n",
    "    train_set_accu = accuracy_score(y_trning_dt_set, train_set_predic)\n",
    "    print(\"Training Accuracy:\", train_set_accu)\n",
    "\n",
    "    # ROC curve for training set\n",
    "    fprate_train_set, tprate_train_set, _ = roc_curve(y_trning_dt_set, train_set_probs[:, 1])\n",
    "    roc_auc_train_set = roc_auc_score(y_trning_dt_set, train_set_predic)\n",
    "    print(\"Area under ROC curve:\", roc_auc_train_set)\n",
    "    plot_roc_curve(fprate_train_set, tprate_train_set, roc_auc_train_set)\n",
    "    \n",
    "    # Test set predictions and probabilities\n",
    "    test_set_predic = algo.predict(x_tsting_dt_set)\n",
    "    test_set_prob = algo.predict_proba(x_tsting_dt_set)\n",
    "\n",
    "    # Classification report for test set\n",
    "    print(\"\\nClassification Report for Test Set:\")\n",
    "    print(classification_report(y_tsting_dt_set, test_set_predic))\n",
    "\n",
    "    # Confusion matrix and plots for test set\n",
    "    print(\"\\nConfusion Matrix for Test Set:\")\n",
    "    tst_confu_mat = confusion_matrix(y_tsting_dt_set, test_set_predic)\n",
    "    plot_confus_mtrx(tst_confu_mat, \"Confusion Matrix for Test Set\")\n",
    "\n",
    "    # Accuracy and ROC curve for test set\n",
    "    accuracy = accuracy_score(y_tsting_dt_set, test_set_predic)\n",
    "    print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "    roc_auc_test_set = roc_auc_score(y_tsting_dt_set, test_set_predic)\n",
    "    print(\"Area under ROC curve:\", roc_auc_test_set)\n",
    "    auc_curves.append(roc_auc_test_set)\n",
    "\n",
    "    fprate, tprate, _ = roc_curve(y_tsting_dt_set, test_set_prob[:, 1])\n",
    "    tprate_curves.append(tprate)\n",
    "    fprate_curves.append(fprate)\n",
    "    plot_roc_curve(fprate, tprate, roc_auc_test_set)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dcbf61-3ee7-4915-b551-215d1c23c927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "logistic_model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "classification_algo_with_feature_imp(logistic_model, x_trning_dt_set, x_tsting_dt_set, y_trning_dt_set, y_tsting_dt_set, independent_features, \"coefficients\",\"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebce654-1fe6-44a1-9fda-74da59ebf7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "data_X = data[independent_features]\n",
    "data_Y = data[dependent_feature]\n",
    "\n",
    "train_set_x, tstng_st_x, train_set_Y, tstng_st_y = train_test_split(data_X, data_Y, test_size=.25, random_state=46)\n",
    "\n",
    "oversampling_data = SMOTE(random_state=0)\n",
    "oversample_X, oversample_Y = oversampling_data.fit_resample(train_set_x, train_set_Y)\n",
    "\n",
    "oversample_X = pds.DataFrame(data=oversample_X, columns=independent_features)\n",
    "oversample_Y = pds.DataFrame(data=oversample_Y, columns=[dependent_feature])  # Corrected line\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0b1920-9759-4732-96a8-a20846db82bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_smote = LogisticRegression()\n",
    "\n",
    "# Function call to breast cancer prediction\n",
    "classification_algo_with_feature_imp(logit_smote, oversample_X, tstng_st_x, oversample_Y, tstng_st_y, independent_features, \"coefficients\",\"Logistic Regression using SMOTE technique\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cb7c90-9e07-4682-b5d5-66c75750f51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "classification_algo_without_feature_imp(knn,oversample_X, tstng_st_x, oversample_Y, tstng_st_y,\"KNN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81954e2b-dbc2-46a7-8d94-a27f8befbf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gaussian Naive Bayes.\n",
    "\n",
    "gnb = GaussianNB(priors=None)\n",
    "\n",
    "classification_algo_without_feature_imp(gnb,oversample_X, tstng_st_x, oversample_Y, tstng_st_y,\"Naive Bayees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54445eef-8173-4e88-b389-b2af3e188d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support Vector Machine\n",
    "\n",
    "\n",
    "svc_lin  = SVC(  kernel='linear',probability=True)\n",
    "\n",
    "\n",
    "classification_algo_with_feature_imp(svc_lin, oversample_X, tstng_st_x, oversample_Y, tstng_st_y, independent_features, \"coefficients\",\"Support Vector Machine\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaa3fdc-4658-4899-8d65-05cacc0ecd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4d38fd-7561-482c-83e5-f0e90d258981",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LightGBMClassifier\n",
    "\n",
    "\n",
    "lgbm_c = LGBMClassifier(verbose=-1)\n",
    "\n",
    "classification_algo_with_feature_imp(lgbm_c, oversample_X, tstng_st_x, oversample_Y, tstng_st_y, independent_features, \"features\",\"Light Gradient-Boosting Machine\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28007eeb-4af5-4d19-843a-b4c68aeb0a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LightGBMClassifier\n",
    "\n",
    "\n",
    "\n",
    "ada_classifier = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "\n",
    "classification_algo_with_feature_imp(ada_classifier, oversample_X, tstng_st_x, oversample_Y, tstng_st_y, independent_features, \"features\",\"Ada Boost Classifier\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b02056a-100d-42c9-a689-b0b51fd03764",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"Logistic Regression\"\n",
    "b = \"Log.R - SMOTE\"\n",
    "c = \"KNN\"\n",
    "d = \"NAIVE BAYES\"\n",
    "e = \"SVM\"\n",
    "f = \"LIGHT GBM CLASSIFIER\"\n",
    "g = \"ADA BOOST CLASSIFIER\"\n",
    "plt.figure(figsize=(8, 6))\n",
    "classifier_names=[a,b,c,d,e,f,g]\n",
    "for fprates, tprates, auc_vals, clf_nmee in zip(fprate_curves, tprate_curves, auc_curves, classifier_names):\n",
    "    plt.plot(fprates, tprates, lw=2, label=f'{clf_nmee} (AUC = {auc_vals:.2f})')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.ylabel('True Positive Rates')\n",
    "plt.xlabel('False Positive Rates')\n",
    "\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curves')\n",
    "plt.legend(loc='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e964868f-c60c-432d-b781-2f01d555884d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Performances\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.offline as pyoff\n",
    "\n",
    "#gives model report in dataframe\n",
    "def mdl_reports(mdl,trning_x,tstingx,trning_y,tstingy,nme) :\n",
    "    mdl.fit(trning_x,trning_y)\n",
    "    predc  = mdl.predict(tstingx)\n",
    "    a     = accuracy_score(tstingy,predc)\n",
    "    rs  = recall_score(tstingy,predc)\n",
    "    p    = precision_score(tstingy,predc)\n",
    "    rc     = roc_auc_score(tstingy,predc)\n",
    "    f1      = f1_score(tstingy,predc) \n",
    "    km = cohen_kappa_score(tstingy,predc)\n",
    "    \n",
    "    df = pds.DataFrame({\"Model\"           : [nme],\n",
    "                       \"Accuracy_score\"  : [a],\n",
    "                       \"Recall_score\"    : [rs],\n",
    "                       \"Precision\"       : [p],\n",
    "                       \"f1_score\"        : [f1],\n",
    "                       \"Area_under_curve\": [rc],\n",
    "                       \"Kappa_metric\"    : [km],\n",
    "                      })\n",
    "    return df\n",
    "\n",
    "mdl1 = mdl_reports(logistic_model, x_trning_dt_set, x_tsting_dt_set, y_trning_dt_set, y_tsting_dt_set,\"Logistic Regression  \")\n",
    "mdl2 = mdl_reports(logit_smote, oversample_X, tstng_st_x, oversample_Y, tstng_st_y,\"Log.R - SMOTE  \")\n",
    "mdl3 = mdl_reports(knn,oversample_X, tstng_st_x, oversample_Y, tstng_st_y,\"KNN Classifier  \")\n",
    "mdl4 = mdl_reports(gnb,oversample_X, tstng_st_x, oversample_Y, tstng_st_y,\"Naive Bayes Classifier  \")\n",
    "mdl5 = mdl_reports(svc_lin,oversample_X, tstng_st_x, oversample_Y, tstng_st_y,\"SVM Classifier  \")\n",
    "mdl6 = mdl_reports(lgbm_c,oversample_X, tstng_st_x, oversample_Y, tstng_st_y,\"LGBM Classifier  \")\n",
    "mdl7 = mdl_reports(ada_classifier,oversample_X, tstng_st_x, oversample_Y, tstng_st_y,\"AdaBoost Classifier  \")\n",
    "\n",
    "#concat all models\n",
    "mdl_perf = pds.concat([mdl1,mdl2,mdl3,mdl4,mdl5,mdl6,mdl7],axis = 0).reset_index()\n",
    "mdl_perf = mdl_perf.drop(columns = \"index\",axis =1)\n",
    "\n",
    "table  = ff.create_table(np.round(mdl_perf,3))\n",
    "pltoff.iplot(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0fedc5-4bd3-4a26-9496-628377b6c5b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7938e4-8cb8-4dbb-8ba4-9e1fac1a503f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
